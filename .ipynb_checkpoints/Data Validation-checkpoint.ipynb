{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bee71-17a2-4e6d-850a-1a8cfe5a4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import CsvExampleGen\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "\n",
    "input_data = external_input(\"data_cleaned.csv\")\n",
    "example_gen = CsvExampleGen(input_base=input_data)\n",
    "example_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94976ad-265e-4fbd-a0a6-110cc33a94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import StatisticsGen\n",
    "\n",
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "statistics_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f898ce-da79-4227-8e04-c4c4f0532e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import SchemaGen\n",
    "\n",
    "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "schema_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b2d75-7f21-4511-9c48-da4982f06b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.components import ExampleValidator\n",
    "\n",
    "example_validator = ExampleValidator(statistics=statistics_gen.outputs['statistics'], schema=schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7659bb3-f1a7-4ea4-9d55-83b41c4d7923",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_validator)  # Assuming 'context' is your pipeline context\n",
    "\n",
    "# Visualize the anomalies\n",
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9757ac0-1f91-4f57-8c96-724ab18d54b9",
   "metadata": {},
   "source": [
    "# Could not manage this part as well, due to technical complexites. My plan included conducting data validation steps to diagnose statistics and detect anomalies in order to make the data ready for modeling part using tensorflow extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a506e-3d0c-45ef-8c2f-2163eda5aa45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
